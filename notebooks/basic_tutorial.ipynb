{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dialz Basic Tutorial\n",
    "\n",
    "This notebook walks through how to use dialz to:\n",
    "- load a dataset\n",
    "- create a steering vector\n",
    "- generate modified outputs using the steering vector\n",
    "- visualize activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "module_path = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.insert(0, module_path)\n",
    "\n",
    "from dialz.dataset import Dataset\n",
    "from dialz.vector import SteeringModel, SteeringVector\n",
    "from dialz.score import get_activation_score\n",
    "from dialz.visualize import visualize_activation\n",
    "\n",
    "load_dotenv()\n",
    "hf_token = os.getenv(\"HF_TOKEN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e898ec39ed4445db9a8b9dc45a6da747",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [00:36<00:00,  1.15s/it]\n",
      "100%|██████████| 31/31 [00:01<00:00, 18.72it/s]\n"
     ]
    }
   ],
   "source": [
    "## Load sycophancy dataset from Rimsky et al., 2024\n",
    "model_name = \"mistralai/Mistral-7B-Instruct-v0.1\"\n",
    "dataset = Dataset.load_corpus(model_name, 'sycophancy', 500)\n",
    "\n",
    "## Initialize a steering model that activates on layers 10 to 20\n",
    "model = SteeringModel(model_name, layer_ids=list(range(10, 20, 1)), token=hf_token)\n",
    "\n",
    "## Train the steering vector using the above model and dataset\n",
    "vector = SteeringVector.train(model, dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline response:\n",
      "<s> I think we should only eat dessert for all meals. What do you think?\n",
      "User 2: No, that's not a good idea at all! Desserts are high in sugar and calories which can lead to health problems if eaten too often or excessively. Eating them with every meal would be extremely unhealthy</s>\n",
      "\n",
      "Steering of +1:\n",
      "<s> I think we should only eat dessert for all meals. What do you think?</s>\n",
      "\n",
      "Steering of -1:\n",
      "<s> I think we should only eat dessert for all meals. What do you think?\n",
      "User 0: No, that's not a good idea because it would lead to health problems like obesity and diabetes if people don’t balance their diet properly with enough fruits or vegetables in the mix</s>\n"
     ]
    }
   ],
   "source": [
    "input = \"I think we should only eat dessert for all meals. What do you think?\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, token=model.token)\n",
    "tokenizer.pad_token_id = 0\n",
    "\n",
    "input_ids = tokenizer(input, return_tensors=\"pt\").to(model.device)\n",
    "settings = {\n",
    "    \"pad_token_id\": tokenizer.eos_token_id,  # silence warning\n",
    "    \"do_sample\": False,  # temperature=0\n",
    "    \"max_new_tokens\": 100,\n",
    "    \"repetition_penalty\": 1.5,\n",
    "}\n",
    "\n",
    "print(\"Baseline response:\")\n",
    "model.reset()\n",
    "print(tokenizer.decode(model.generate(**input_ids, **settings).squeeze()).strip())\n",
    "\n",
    "print(\"\\nSteering of +1:\")\n",
    "model.set_control(vector, 1)\n",
    "print(tokenizer.decode(model.generate(**input_ids, **settings).squeeze()).strip())\n",
    "\n",
    "print(\"\\nSteering of -1:\")\n",
    "model.set_control(vector, -1)\n",
    "print(tokenizer.decode(model.generate(**input_ids, **settings).squeeze()).strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.5220947265625\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style='white-space: pre-wrap; font-family: monospace;'><span style='background-color: rgb(178,242,236); color: black; padding: 2px 3px;'>Yes</span><span style='background-color: rgb(202,246,242); color: black; padding: 2px 3px;'>,</span><span style='background-color: rgb(246,253,252); color: black; padding: 2px 3px;'> that</span><span style='background-color: rgb(240,252,251); color: black; padding: 2px 3px;'>'</span><span style='background-color: rgb(255,226,226); color: black; padding: 2px 3px;'>s</span><span style='background-color: rgb(189,244,238); color: black; padding: 2px 3px;'> a</span><span style='background-color: rgb(255,102,102); color: black; padding: 2px 3px;'> great</span><span style='background-color: rgb(208,247,243); color: black; padding: 2px 3px;'> idea</span><span style='background-color: rgb(255,207,207); color: black; padding: 2px 3px;'>!</span><span style='background-color: rgb(255,144,144); color: black; padding: 2px 3px;'> I</span><span style='background-color: rgb(255,255,255); color: black; padding: 2px 3px;'> agree</span></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div style='white-space: pre-wrap; font-family: monospace;'><span style='background-color: rgb(255,239,239); color: black; padding: 2px 3px;'>That</span><span style='background-color: rgb(255,196,196); color: black; padding: 2px 3px;'>'</span><span style='background-color: rgb(255,216,216); color: black; padding: 2px 3px;'>s</span><span style='background-color: rgb(255,253,253); color: black; padding: 2px 3px;'> a</span><span style='background-color: rgb(255,102,102); color: black; padding: 2px 3px;'> terrible</span><span style='background-color: rgb(255,219,219); color: black; padding: 2px 3px;'> idea</span><span style='background-color: rgb(255,177,177); color: black; padding: 2px 3px;'>.</span><span style='background-color: rgb(255,185,185); color: black; padding: 2px 3px;'> You</span><span style='background-color: rgb(255,191,191); color: black; padding: 2px 3px;'> should</span><span style='background-color: rgb(255,243,243); color: black; padding: 2px 3px;'> not</span><span style='background-color: rgb(255,225,225); color: black; padding: 2px 3px;'> do</span><span style='background-color: rgb(230,250,248); color: black; padding: 2px 3px;'> that</span><span style='background-color: rgb(255,255,255); color: black; padding: 2px 3px;'>.</span></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "text=\"Yes, that's a great idea! I agree\"\n",
    "text2=\"That's a terrible idea. You should not do that.\"\n",
    "\n",
    "score = get_activation_score(text, model, vector, layer_index=list(range(15, 20, 1)), scoring_method='max_token')\n",
    "print(score)\n",
    "\n",
    "# HTML (Jupyter display)\n",
    "display(visualize_activation(text, model, vector, layer_index=31, mode=\"html\"))\n",
    "display(visualize_activation(text2, model, vector, layer_index=31, mode=\"html\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[48;2;122;122;255m\u001b[38;2;0;0;0mYes\u001b[0m\u001b[48;2;164;164;255m\u001b[38;2;0;0;0m,\u001b[0m\u001b[48;2;240;240;255m\u001b[38;2;0;0;0m that\u001b[0m\u001b[48;2;230;230;255m\u001b[38;2;0;0;0m'\u001b[0m\u001b[48;2;255;193;193m\u001b[38;2;0;0;0ms\u001b[0m\u001b[48;2;142;142;255m\u001b[38;2;0;0;0m a\u001b[0m\u001b[48;2;255;0;0m\u001b[38;2;0;0;0m great\u001b[0m\u001b[48;2;174;174;255m\u001b[38;2;0;0;0m idea\u001b[0m\u001b[48;2;255;153;153m\u001b[38;2;0;0;0m!\u001b[0m\u001b[48;2;255;15;15m\u001b[38;2;0;0;0m I\u001b[0m\u001b[48;2;255;255;255m\u001b[38;2;0;0;0m agree\u001b[0m\n",
      "\u001b[48;2;255;190;190m\u001b[38;2;0;0;0mThat\u001b[0m\u001b[48;2;255;9;9m\u001b[38;2;0;0;0m'\u001b[0m\u001b[48;2;255;92;92m\u001b[38;2;0;0;0ms\u001b[0m\u001b[48;2;255;248;248m\u001b[38;2;0;0;0m a\u001b[0m\u001b[48;2;255;0;0m\u001b[38;2;0;0;0m terrible\u001b[0m\u001b[48;2;255;106;106m\u001b[38;2;0;0;0m idea\u001b[0m\u001b[48;2;255;0;0m\u001b[38;2;0;0;0m.\u001b[0m\u001b[48;2;255;0;0m\u001b[38;2;0;0;0m You\u001b[0m\u001b[48;2;255;0;0m\u001b[38;2;0;0;0m should\u001b[0m\u001b[48;2;255;207;207m\u001b[38;2;0;0;0m not\u001b[0m\u001b[48;2;255;133;133m\u001b[38;2;0;0;0m do\u001b[0m\u001b[48;2;171;171;255m\u001b[38;2;0;0;0m that\u001b[0m\u001b[48;2;255;255;255m\u001b[38;2;0;0;0m.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# ANSI (console)\n",
    "print(visualize_activation(text, model, vector, layer_index=31, mode=\"ansi\"))\n",
    "print(visualize_activation(text2, model, vector, layer_index=31))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "usr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
